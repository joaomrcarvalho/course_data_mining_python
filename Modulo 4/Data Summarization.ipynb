{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resumo de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://joaomrcarvalho.github.io/images/multi-doc-summary-800x638.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A função GroupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://joaomrcarvalho.github.io/datasets/dm/phone_data.csv', index_col='index')\n",
    "\n",
    "print(data.head(10))\n",
    "print('-----------------------------------------------------------------------------------------')\n",
    "\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dateutil\n",
    "\n",
    "data['date'] = data['date'].apply(dateutil.parser.parse, dayfirst=True)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = data.groupby(['month'])\n",
    "\n",
    "print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(group.groups.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(group.groups['2014-11'])\n",
    "\n",
    "print('------------------------------------------------')\n",
    "\n",
    "print(len(group.groups['2014-11']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(group.max())\n",
    "\n",
    "print('------------------------------------------------')\n",
    "\n",
    "print(group.max()['duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(group.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(group.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = data.groupby('month').agg({'duration':'sum', 'item':'first', 'network':'last'})\n",
    "\n",
    "print(group)\n",
    "print('----------------------------------------------------------------------------')\n",
    "\n",
    "group = data.groupby('month', as_index=False).agg({'duration':'sum', 'item':'first', 'network':'last'})\n",
    "print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = data.groupby('month').agg({\"duration\":['max','mean','sum'] ,\"item\":'first','network':'last'})\n",
    "\n",
    "print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = data.groupby(['month','item']).agg({'duration':'sum','network_type':'count','date':['last','nunique']})\n",
    "print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = data.groupby('month', as_index=False).agg({\"duration\":['max','mean','sum'] ,\"item\":'first','network':'last'})\n",
    "print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group.columns = group.columns.droplevel(level=0)\n",
    "\n",
    "print(group)\n",
    "\n",
    "print('----------------------------------------------------------------------------------------------')\n",
    "\n",
    "group.rename(columns={ 'max':'max_duration','mean':'mean_duration','sum':'sum_duration'}, inplace=True)\n",
    "print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "group = data.groupby('month', as_index=False).agg({'duration':['max','mean','sum'] ,'item':['first','last'],'network':'last'})\n",
    "\n",
    "print(group)\n",
    "print('--------------------------------------------------------------------------------------------------')\n",
    "\n",
    "print(group.columns.ravel())\n",
    "\n",
    "print('--------------------------------------------------------------------------------------------------')\n",
    "\n",
    "group.columns = [\"_\".join(x) for x in group.columns.ravel()]\n",
    "print(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sugestão de exercício:** Gerar um novo DataFrame a partir do conjunto de dados adults, agrupado por idade e aplicar-lhe as operações sum, min e max em três colunas distintas. No final, organizar os dados de forma intuitiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinar Múltiplos DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://joaomrcarvalho.github.io/datasets/dm/iris.data',names=['x1','x2','x3','x4','especie'])\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenar DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_10 = data.head(10)\n",
    "print(first_10)\n",
    "\n",
    "print('--------------------------------------------------------')\n",
    "\n",
    "last_10 = data.tail(10)\n",
    "print(last_10)\n",
    "\n",
    "print('--------------------------------------------------------')\n",
    "\n",
    "last_10 = last_10.reset_index(drop=True) \n",
    "print(last_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_vertical = pd.concat([first_10,last_10], axis=0)\n",
    "print(concat_vertical)\n",
    "\n",
    "print('-----------------------------------------------------------------------------')\n",
    "\n",
    "concat_horizontal = pd.concat([first_10,last_10], axis=1)\n",
    "print(concat_horizontal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(concat_vertical.index))\n",
    "\n",
    "print('--------------------------------------------------------------------')\n",
    "\n",
    "concat_vertical = pd.concat([first_10,last_10],axis=0,ignore_index=True)\n",
    "print(list(concat_vertical.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sugestão de exercício:** Renomear as colunas do dataframe last_10, eliminar a coluna relativa à espécie e concatenar com o dataframe first_10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A função  pd.merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame({'index_1':[1,2,3,4,6,7,9,10],\n",
    "                     'nomes':['joão','alexandre','andré','ana','bernardo','cláudia','rodrigo','maria'],\n",
    "                     'altura':[1.6,1.8,1.7,1.75,1.88,2.1,1.87,1.65]})\n",
    "\n",
    "df_2 = pd.DataFrame({'index_2':[1,2,3,4,5,6,7,8],\n",
    "                     'peso':[84,102,63,79,90,110,87,59]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_inner = pd.merge(left=df_1,right=df_2, left_on='index_1', right_on='index_2',how='inner')\n",
    "\n",
    "print(merged_inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_outer = pd.merge(left=df_1,right=df_2, left_on='index_1', right_on='index_2',how='outer')\n",
    "\n",
    "print(merged_outer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_left = pd.merge(left=df_1,right=df_2, left_on='index_1', right_on='index_2',how='left')\n",
    "\n",
    "print(merged_left)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "merged_right = pd.merge(left=df_1,right=df_2, left_on='index_1', right_on='index_2',how='right')\n",
    "\n",
    "print(merged_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A tabela Pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xlrd\n",
    "\n",
    "data = pd.read_excel('https://joaomrcarvalho.github.io/datasets/dm/sales-funnel.xlsx')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvt_table = pd.pivot_table(data, index=['Name'])\n",
    "\n",
    "print(pvt_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvt_table = pd.pivot_table(data,index=['Name'],values=['Price'])\n",
    "\n",
    "print(pvt_table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvt_table = pd.pivot_table(data,index=['Rep','Name'])\n",
    "\n",
    "print(pvt_table)\n",
    "\n",
    "print('----------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "pvt_table = pd.pivot_table(data,index=['Name','Rep'])\n",
    "\n",
    "print(pvt_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvt_table = pd.pivot_table(data,index=[\"Rep\",\"Name\",\"Product\"],values=[\"Price\",\"Quantity\"])\n",
    "print(pvt_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = pvt_table.loc['Cedric Moss']\n",
    "\n",
    "print(rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sugestão de exercício:** Salvar as subtabelas em arquivos independentes no formato excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvt_table = pd.pivot_table(data,index=[\"Manager\",\"Rep\"],values=[\"Price\"],aggfunc=['sum'])\n",
    "\n",
    "print(pvt_table)\n",
    "\n",
    "print('-----------------------------------------------------------------------------------------------------')\n",
    "\n",
    "pvt_table = pd.pivot_table(data,index=[\"Manager\",\"Rep\"],values=[\"Price\"],aggfunc=['sum','mean'])\n",
    "\n",
    "print(pvt_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvt_table = pd.pivot_table(data,index=[\"Manager\",\"Rep\"],values=[\"Price\"],aggfunc=['sum'],columns=['Product'])\n",
    "\n",
    "print(pvt_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvt_table = pd.pivot_table(data,index=[\"Manager\",\"Rep\"],values=[\"Price\"],aggfunc=['sum'],columns=['Product'],\n",
    "                          fill_value=0)\n",
    "\n",
    "print(pvt_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvt_table = pd.pivot_table(data,index=[\"Manager\",\"Rep\"],values=[\"Price\"],aggfunc=['sum','mean'],columns=['Product'],\n",
    "                          fill_value=0)\n",
    "\n",
    "pvt_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvt_table = pd.pivot_table(data,index=[\"Manager\",\"Rep\",\"Product\"],values=[\"Price\"],aggfunc=['sum','mean'],\n",
    "                          fill_value=0)\n",
    "pvt_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O padrão split-apply-combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fic_data = pd.DataFrame({'size':['GG','G','M','P','GG','G','M','P','GG','G','M','P','GG','G','M','P','M','P'],\n",
    "            'sale':[1000,1500,800,900,2000,1450,1200,3000,2500,2000,1600,900,901,1500,1420,1300,4000,3500],\n",
    "            'transaction':[50,75,410,460,115,60,35,125,125,55,65,430,490,150,85,115,140,80],\n",
    "             'type':['D','D','D','D','D','D','D','D','D','B','B','B','B','B','B','B','B','B']})\n",
    "\n",
    "print(fic_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_data = fic_data.groupby('size')\n",
    "\n",
    "gp_data.get_group('G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,value in gp_data:\n",
    "    print('Grupo',key)\n",
    "    print(value)\n",
    "    print('-------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_gp_data = gp_data.get_group('G').groupby('type')\n",
    "\n",
    "sub_gp_data.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_data = fic_data.groupby(['type','size'], as_index=True).agg({'sale':['sum','mean']})\n",
    "\n",
    "\n",
    "print(gp_data)\n",
    "\n",
    "print('--------------------------------------------------------')\n",
    "\n",
    "gp_data = fic_data.groupby(['type','size'], as_index=False).agg({'sale':['sum','mean']})\n",
    "\n",
    "print(gp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: 'high' if x > 3000 else 'low'\n",
    "\n",
    "\n",
    "gp_data = fic_data.groupby(['type','size'], as_index=False).agg({'sale':['sum','mean']})\n",
    "print(gp_data)\n",
    "\n",
    "print(\"-----------------------------------------\")\n",
    "\n",
    "gp_data['level'] = gp_data['sale']['sum'].apply(f)\n",
    "print(gp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_data.columns = [\"_\".join(x) for x in gp_data.columns.ravel()]\n",
    "\n",
    "print(gp_data)\n",
    "\n",
    "print('------------------------------------------------------------------')\n",
    "\n",
    "lv_gp_data = gp_data.groupby('level_')\n",
    "\n",
    "print(lv_gp_data.get_group('low'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fic_data = pd.DataFrame({'size':['GG','G','M','P','GG','G','M','P','GG','G','M','P','GG','G','M','P','M','P'],\n",
    "            'sale':[1000,1500,800,900,2000,1450,1200,3000,2500,2000,1600,900,901,1500,1420,1300,4000,3500],\n",
    "            'transaction':[50,75,410,460,115,60,35,125,125,55,65,430,490,150,85,115,140,80],\n",
    "             'type':['D','D','D','D','D','D','D','D','D','B','B','B','B','B','B','B','B','B']})\n",
    "\n",
    "\n",
    "print(fic_data.head(5))\n",
    "\n",
    "print('--------------------------------------------------------------------')\n",
    "\n",
    "print(fic_data.groupby('type', as_index=True).std())\n",
    "\n",
    "print('--------------------------------------------------------------------')\n",
    "\n",
    "fic_data['sale_std'] = fic_data.groupby('type', as_index=True)['sale'].transform('std')\n",
    "\n",
    "print(fic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fic_data = pd.DataFrame({'size':['GG','G','M','P','GG','G','M','P','GG','G','M','P','GG','G','M','P','M','P'],\n",
    "            'sale':[1000,1500,800,900,2000,1450,1200,3000,2500,2000,1600,900,901,1500,1420,1300,4000,3500],\n",
    "            'transaction':[50,75,410,460,115,60,35,125,125,55,65,430,490,150,85,115,140,80],\n",
    "             'type':['D','D','D','D','D','D','D','D','D','B','B','B','B','B','B','B','B','B']})\n",
    "\n",
    "transformacoes = ['std','sum','mean','count']\n",
    "\n",
    "for trans in transformacoes:\n",
    "    fic_data['sale_{}'.format(trans)] = fic_data.groupby(['type','size'], as_index=True)['sale'].transform(trans)\n",
    "    \n",
    "print(fic_data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fic_data['sale_stdartized'] = ((fic_data['sale'] - fic_data['sale_mean'])/fic_data['sale_std'])\n",
    "\n",
    "print(fic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fic_data = pd.DataFrame({'size':['GG','G','M','P','GG','G','M','P','GG','G','M','P','GG','G','M','P','M','P'],\n",
    "            'sale':[1000,1500,800,900,2000,1450,1200,3000,2500,2000,1600,900,901,1500,1420,1300,4000,3500],\n",
    "            'transaction':[50,75,410,460,115,60,35,125,125,55,65,430,490,150,85,115,140,80],\n",
    "             'type':['D','D','D','D','D','D','D','D','D','B','B','B','B','B','B','B','B','B']})\n",
    "\n",
    "\n",
    "group_data = fic_data.groupby('size')\n",
    "\n",
    "print(group_data['transaction'].mean())\n",
    "\n",
    "print('-----------------------------------------------------------------------------------------------')\n",
    "\n",
    "mean_dic = {\n",
    "           'P':group_data['transaction'].mean().loc['P'],\n",
    "           'M':group_data['transaction'].mean().loc['M'],\n",
    "           'G':group_data['transaction'].mean().loc['G'],\n",
    "           'GG':group_data['transaction'].mean().loc['GG']\n",
    "            }\n",
    "\n",
    "\n",
    "fill_data = pd.DataFrame(columns=fic_data.columns)\n",
    "\n",
    "for key, group in group_data:\n",
    "    seleccao = group[group['transaction'] > mean_dic[key]]\n",
    "    fill_data = fill_data.append(seleccao)\n",
    "    \n",
    "\n",
    "print(fill_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = fic_data.groupby('size',as_index=True)['sale'].mean()\n",
    "\n",
    "print(type(group))\n",
    "\n",
    "print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = fic_data.groupby('size',as_index=True).agg({'sale':np.mean,'transaction':np.sum})\n",
    "\n",
    "print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = fic_data.groupby('size',as_index=False)['sale'].mean()\n",
    "\n",
    "print(group)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
